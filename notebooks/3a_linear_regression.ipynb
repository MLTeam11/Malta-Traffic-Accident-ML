{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8128e0-5510-42a2-abd5-ca05c7110f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all the packages I need...\n",
      "âœ… All packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Malta Traffic Accident Analysis - Logistic Regression\n",
    "# ICS5110 Applied Machine Learning Assignment\n",
    "# Student: Naomi Thornley & Giulia-Maria Montebonello\n",
    "# Date: January 2026\n",
    "\n",
    "\"\"\"\n",
    "This notebook implements Logistic Regression to predict accident severity.\n",
    "\n",
    "Research Questions Addressed:\n",
    "RQ1: How accurately can ML predict minor vs severe injuries?\n",
    "     â†’ Measure accuracy, precision, recall, F1-score\n",
    "RQ2: Which features matter most for predicting severity?\n",
    "     â†’ Analyze logistic regression coefficients\n",
    "RQ3: Does motorcycle involvement increase severity?\n",
    "     â†’ Check motorcycle coefficient significance\n",
    "\n",
    "Our approach:\n",
    "1. Prepare the data (encode categories, scale features)\n",
    "2. Split into train/test (80/20)\n",
    "3. Train logistic regression\n",
    "4. Evaluate performance\n",
    "5. Interpret coefficients to answer RQs\n",
    "\"\"\"\n",
    "\n",
    "# IMPORT LIBRARIES\n",
    "\n",
    "print(\"Loading all the packages I need...\")\n",
    "\n",
    "# For working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# For making charts\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings to make output cleaner\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Hide warning messages\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "%matplotlib inline  \n",
    "\n",
    "print(\"âœ… All packages loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc47b12-c6da-4a68-832f-827adede7320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING MY ML-READY DATA\n",
      "======================================================================\n",
      "\n",
      "âœ… Data loaded!\n",
      "   I have 318 accident records\n",
      "   With 33 columns\n",
      "\n",
      "ðŸ“Š What I'm predicting (severity_binary):\n",
      "severity_binary\n",
      "high    251\n",
      "low      67\n",
      "Name: count, dtype: int64\n",
      "\n",
      "   High severity (fatal/grievous): 251 (78.9%)\n",
      "   Low severity (serious/slight): 67 (21.1%)\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE CLEAN DATA\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING MY ML-READY DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load the dataset I prepared in Notebook 1\n",
    "df = pd.read_csv('data/processed/accidents_ml_ready.csv')\n",
    "\n",
    "print(f\"\\nâœ… Data loaded!\")\n",
    "print(f\"   I have {len(df)} accident records\")\n",
    "print(f\"   With {len(df.columns)} columns\")\n",
    "\n",
    "# Let's see what I'm trying to predict\n",
    "print(f\"\\nðŸ“Š What I'm predicting (severity_binary):\")\n",
    "print(df['severity_binary'].value_counts())\n",
    "\n",
    "high_count = (df['severity_binary'] == 'high').sum()\n",
    "low_count = (df['severity_binary'] == 'low').sum()\n",
    "print(f\"\\n   High severity (fatal/grievous): {high_count} ({high_count/len(df)*100:.1f}%)\")\n",
    "print(f\"   Low severity (serious/slight): {low_count} ({low_count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9829df40-3ee3-45a9-9d8d-6e4cc5b01cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SELECTING FEATURES FOR MY MODEL\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤” Which features should I include?\n",
      "   I need features that might predict severity AND answer my research questions!\n",
      "\n",
      "ðŸ“‹ My feature groups:\n",
      "   â° Temporal: ['month', 'is_weekend', 'is_holiday', 'has_time']\n",
      "   ðŸ“ Location: ['has_location']\n",
      "   ðŸŒ¦ï¸ Weather: ['temperature', 'precipitation', 'wind_speed', 'is_rainy', 'is_windy']\n",
      "   ðŸš— Vehicle: ['has_motorcycle']\n",
      "   ðŸ“ Categorical (need encoding): ['day_of_week', 'region', 'weather_condition', 'vehicle_category', 'time_of_day', 'season', 'area_type']\n",
      "\n",
      "âœ… I'm starting with 18 features\n",
      "   (11 numerical + 7 categorical)\n"
     ]
    }
   ],
   "source": [
    "# DECIDING WHICH FEATURES TO USE\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SELECTING FEATURES FOR MY MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ¤” Which features should I include?\")\n",
    "print(\"   I need features that might predict severity AND answer my research questions!\")\n",
    "\n",
    "# Features I'll use - grouped by type\n",
    "temporal_features = ['month', 'is_weekend', 'is_holiday', 'has_time']\n",
    "location_features = ['has_location']\n",
    "weather_features = ['temperature', 'precipitation', 'wind_speed', 'is_rainy', 'is_windy']\n",
    "vehicle_features = ['has_motorcycle']  # Important for RQ3!\n",
    "\n",
    "# Categorical features (need to encode these as numbers)\n",
    "categorical_features = [\n",
    "    'day_of_week',      # Monday, Tuesday, etc.\n",
    "    'region',           # Malta vs Gozo\n",
    "    'weather_condition',# Clear, rain, etc.\n",
    "    'vehicle_category', # Motorcycle involved, car only, etc.\n",
    "    'time_of_day',      # Morning, afternoon, etc.\n",
    "    'season',           # Summer, winter, etc.\n",
    "    'area_type'         # Urban vs rural\n",
    "]\n",
    "\n",
    "print(f\"\\nðŸ“‹ My feature groups:\")\n",
    "print(f\"   â° Temporal: {temporal_features}\")\n",
    "print(f\"   ðŸ“ Location: {location_features}\")\n",
    "print(f\"   ðŸŒ¦ï¸ Weather: {weather_features}\")\n",
    "print(f\"   ðŸš— Vehicle: {vehicle_features}\")\n",
    "print(f\"   ðŸ“ Categorical (need encoding): {categorical_features}\")\n",
    "\n",
    "# Count total features\n",
    "numerical_features = temporal_features + location_features + weather_features + vehicle_features\n",
    "total_features = len(numerical_features) + len(categorical_features)\n",
    "\n",
    "print(f\"\\nâœ… I'm starting with {total_features} features\")\n",
    "print(f\"   ({len(numerical_features)} numerical + {len(categorical_features)} categorical)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf31519-ccba-4a1f-84ef-6e6ab44eb2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENCODING CATEGORICAL FEATURES\n",
      "======================================================================\n",
      "\n",
      "ðŸ”„ Problem: ML models need numbers, not text!\n",
      "   'Monday', 'Tuesday' â†’ need to become numbers\n",
      "   Solution: One-hot encoding (create binary columns)\n",
      "\n",
      "ðŸ“‹ Categorical features to encode:\n",
      "   day_of_week: 7 unique values\n",
      "   region: 3 unique values\n",
      "   weather_condition: 3 unique values\n",
      "   vehicle_category: 3 unique values\n",
      "   time_of_day: 5 unique values\n",
      "   season: 3 unique values\n",
      "   area_type: 3 unique values\n",
      "   hour_category: 5 unique values\n",
      "\n",
      "âœ… Encoding done!\n",
      "   Before encoding: 33 columns\n",
      "   After encoding: 49 columns\n",
      "\n",
      "âœ… After encoding, I have 36 features for modeling\n",
      "\n",
      "ðŸ“‹ Here are all my features:\n",
      "    1. month\n",
      "    2. is_weekend\n",
      "    3. has_time\n",
      "    4. has_location\n",
      "    5. has_motorcycle\n",
      "    6. is_holiday\n",
      "    7. temperature\n",
      "    8. precipitation\n",
      "    9. wind_speed\n",
      "   10. is_rainy\n",
      "   11. is_foggy\n",
      "   12. is_windy\n",
      "   13. day_of_week_Monday\n",
      "   14. day_of_week_Saturday\n",
      "   15. day_of_week_Sunday\n",
      "   16. day_of_week_Thursday\n",
      "   17. day_of_week_Tuesday\n",
      "   18. day_of_week_Wednesday\n",
      "   19. region_Malta\n",
      "   20. region_unknown\n",
      "   21. weather_condition_partly_cloudy\n",
      "   22. weather_condition_rain\n",
      "   23. vehicle_category_motorcycle_involved\n",
      "   24. vehicle_category_other\n",
      "   25. time_of_day_evening\n",
      "   26. time_of_day_morning\n",
      "   27. time_of_day_night\n",
      "   28. time_of_day_unknown\n",
      "   29. season_summer\n",
      "   30. season_winter\n",
      "   31. area_type_unknown\n",
      "   32. area_type_urban\n",
      "   33. hour_category_night\n",
      "   34. hour_category_rush_evening\n",
      "   35. hour_category_rush_morning\n",
      "   36. hour_category_unknown\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONVERTING CATEGORIES TO NUMBERS\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"ENCODING CATEGORICAL FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ”„ Problem: ML models need numbers, not text!\")\n",
    "print(\"   'Monday', 'Tuesday' â†’ need to become numbers\")\n",
    "print(\"   Solution: One-hot encoding (create binary columns)\")\n",
    "\n",
    "# Make a copy so I don't mess up my original data\n",
    "df_model = df.copy()\n",
    "\n",
    "# ALL categorical features that need encoding (COMPLETE LIST)\n",
    "categorical_features = [\n",
    "    'day_of_week',       # Monday, Tuesday, etc.\n",
    "    'region',            # Malta vs Gozo\n",
    "    'weather_condition', # Clear, rain, etc.\n",
    "    'vehicle_category',  # Motorcycle involved, car only, etc.\n",
    "    'time_of_day',       # Morning, afternoon, etc.\n",
    "    'season',            # Summer, winter, etc.\n",
    "    'area_type',         # Urban vs rural\n",
    "    'hour_category'      # Rush hour categories - WE MISSED THIS!\n",
    "]\n",
    "\n",
    "print(f\"\\nðŸ“‹ Categorical features to encode:\")\n",
    "for feat in categorical_features:\n",
    "    unique_vals = df_model[feat].nunique()\n",
    "    print(f\"   {feat}: {unique_vals} unique values\")\n",
    "\n",
    "# One-hot encode the categorical features\n",
    "# drop_first=True avoids multicollinearity (important for logistic regression!)\n",
    "df_encoded = pd.get_dummies(df_model, columns=categorical_features, drop_first=True)\n",
    "\n",
    "print(f\"\\nâœ… Encoding done!\")\n",
    "print(f\"   Before encoding: {len(df_model.columns)} columns\")\n",
    "print(f\"   After encoding: {len(df_encoded.columns)} columns\")\n",
    "\n",
    "# Figure out which columns are my features (exclude metadata and target)\n",
    "columns_to_exclude = [\n",
    "    'title', 'content', 'date', 'source', 'time', \n",
    "    'severity', 'severity_binary', 'severity_3class',  # Target variables\n",
    "    'vehicles', 'location', 'weather_code',  # Text columns\n",
    "    'year', 'hour', 'month_name', 'date_modified'  # Not using these directly\n",
    "]\n",
    "\n",
    "# Get all columns that aren't excluded\n",
    "feature_columns = [col for col in df_encoded.columns if col not in columns_to_exclude]\n",
    "\n",
    "print(f\"\\nâœ… After encoding, I have {len(feature_columns)} features for modeling\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Here are all my features:\")\n",
    "for i, feat in enumerate(feature_columns, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda392be-e279-47f7-84fd-02c796a4319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SETTING UP X AND y\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š In ML, we call:\n",
      "   X = features (what I use to predict)\n",
      "   y = target (what I'm trying to predict)\n",
      "\n",
      "âœ… X (features) shape: (318, 36)\n",
      "   â†’ 318 accidents (rows)\n",
      "   â†’ 36 features (columns)\n",
      "\n",
      "âœ… y (target) shape: (318,)\n",
      "   Distribution:\n",
      "   â†’ Class 1 (high severity): 251 accidents (78.9%)\n",
      "   â†’ Class 0 (low severity): 67 accidents (21.1%)\n",
      "\n",
      "ðŸ” Checking for missing values...\n",
      "   âœ… No missing values - perfect!\n"
     ]
    }
   ],
   "source": [
    "# PREPARING X (FEATURES) AND y (TARGET)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SETTING UP X AND y\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š In ML, we call:\")\n",
    "print(\"   X = features (what I use to predict)\")\n",
    "print(\"   y = target (what I'm trying to predict)\")\n",
    "\n",
    "# X = all my features\n",
    "X = df_encoded[feature_columns]\n",
    "\n",
    "# y = target variable (severity)\n",
    "# Convert 'high'/'low' to 1/0 for the model\n",
    "y = (df_encoded['severity_binary'] == 'high').astype(int)\n",
    "# Now: 1 = high severity, 0 = low severity\n",
    "\n",
    "print(f\"\\nâœ… X (features) shape: {X.shape}\")\n",
    "print(f\"   â†’ {X.shape[0]} accidents (rows)\")\n",
    "print(f\"   â†’ {X.shape[1]} features (columns)\")\n",
    "\n",
    "print(f\"\\nâœ… y (target) shape: {y.shape}\")\n",
    "print(f\"   Distribution:\")\n",
    "print(f\"   â†’ Class 1 (high severity): {y.sum()} accidents ({y.sum()/len(y)*100:.1f}%)\")\n",
    "print(f\"   â†’ Class 0 (low severity): {(y == 0).sum()} accidents ({(y == 0).sum()/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Quick check for missing values\n",
    "print(f\"\\nðŸ” Checking for missing values...\")\n",
    "missing_count = X.isnull().sum().sum()\n",
    "\n",
    "if missing_count > 0:\n",
    "    print(f\"   âš ï¸ Found {missing_count} missing values\")\n",
    "    print(f\"   Filling them with 0 (simple approach)\")\n",
    "    X = X.fillna(0)\n",
    "    print(f\"   âœ… Done!\")\n",
    "else:\n",
    "    print(f\"   âœ… No missing values - perfect!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e14cb2-b15b-4dd0-b897-65019ff6c77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SPLITTING DATA: TRAIN SET vs TEST SET\n",
      "======================================================================\n",
      "\n",
      "ðŸ“š Why split?\n",
      "   â†’ Train set: Model learns from this (80% of data)\n",
      "   â†’ Test set: Model is evaluated on this (20% of data)\n",
      "   â†’ This way I can see if the model generalizes to new data!\n",
      "\n",
      "âœ… Split complete!\n",
      "\n",
      "ðŸ“Š Training set (model will learn from this):\n",
      "   â†’ 254 accidents\n",
      "   â†’ High severity: 200 (78.7%)\n",
      "   â†’ Low severity: 54 (21.3%)\n",
      "\n",
      "ðŸ“Š Test set (will test the model on this):\n",
      "   â†’ 64 accidents\n",
      "   â†’ High severity: 51 (79.7%)\n",
      "   â†’ Low severity: 13 (20.3%)\n"
     ]
    }
   ],
   "source": [
    "# SPLITTING INTO TRAINING AND TEST SETS\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SPLITTING DATA: TRAIN SET vs TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“š Why split?\")\n",
    "print(\"   â†’ Train set: Model learns from this (80% of data)\")\n",
    "print(\"   â†’ Test set: Model is evaluated on this (20% of data)\")\n",
    "print(\"   â†’ This way I can see if the model generalizes to new data!\")\n",
    "\n",
    "# Split the data\n",
    "# test_size=0.2 means 20% for testing\n",
    "# random_state=42 makes it reproducible (same split every time)\n",
    "# stratify=y keeps the same class balance in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Split complete!\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Training set (model will learn from this):\")\n",
    "print(f\"   â†’ {len(X_train)} accidents\")\n",
    "print(f\"   â†’ High severity: {y_train.sum()} ({y_train.sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"   â†’ Low severity: {(y_train == 0).sum()} ({(y_train == 0).sum()/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Test set (will test the model on this):\")\n",
    "print(f\"   â†’ {len(X_test)} accidents\")\n",
    "print(f\"   â†’ High severity: {y_test.sum()} ({y_test.sum()/len(y_test)*100:.1f}%)\")\n",
    "print(f\"   â†’ Low severity: {(y_test == 0).sum()} ({(y_test == 0).sum()/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21746689-b424-4fd8-8bf6-9701ce830908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SCALING FEATURES TO THE SAME RANGE\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤” Why do I need to scale?\n",
      "   Problem: My features are on very different scales:\n",
      "   â†’ temperature: 12-30 (range of ~18)\n",
      "   â†’ wind_speed: 6-49 (range of ~43)\n",
      "   â†’ is_weekend: 0-1 (range of 1)\n",
      "\n",
      "   Logistic regression is sensitive to scale!\n",
      "   â†’ Features with bigger ranges would dominate\n",
      "   â†’ Scaling puts everything on the same scale\n",
      "\n",
      "ðŸ”§ Solution: StandardScaler\n",
      "   Transforms each feature to: mean=0, std=1\n",
      "\n",
      "âœ… Scaling complete!\n",
      "\n",
      "ðŸ“Š Example: temperature\n",
      "   Before scaling: mean=21.06, std=5.46\n",
      "   After scaling:  mean=-0.00, std=1.00\n",
      "   â†’ Now it's standardized (meanâ‰ˆ0, stdâ‰ˆ1)!\n"
     ]
    }
   ],
   "source": [
    "# SCALING FEATURES \n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SCALING FEATURES TO THE SAME RANGE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ¤” Why do I need to scale?\")\n",
    "print(\"   Problem: My features are on very different scales:\")\n",
    "print(\"   â†’ temperature: 12-30 (range of ~18)\")\n",
    "print(\"   â†’ wind_speed: 6-49 (range of ~43)\")\n",
    "print(\"   â†’ is_weekend: 0-1 (range of 1)\")\n",
    "print(\"\\n   Logistic regression is sensitive to scale!\")\n",
    "print(\"   â†’ Features with bigger ranges would dominate\")\n",
    "print(\"   â†’ Scaling puts everything on the same scale\")\n",
    "\n",
    "print(\"\\nðŸ”§ Solution: StandardScaler\")\n",
    "print(\"   Transforms each feature to: mean=0, std=1\")\n",
    "\n",
    "# Create the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# IMPORTANT: Fit the scaler on training data only!\n",
    "# Then use it to transform both train and test\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame so I keep the column names\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(f\"\\nâœ… Scaling complete!\")\n",
    "\n",
    "# Show an example to prove it worked\n",
    "temp_col = [col for col in X_train.columns if 'temperature' in col.lower()]\n",
    "if temp_col:\n",
    "    col_name = temp_col[0]\n",
    "    print(f\"\\nðŸ“Š Example: {col_name}\")\n",
    "    print(f\"   Before scaling: mean={X_train[col_name].mean():.2f}, std={X_train[col_name].std():.2f}\")\n",
    "    print(f\"   After scaling:  mean={X_train_scaled[col_name].mean():.2f}, std={X_train_scaled[col_name].std():.2f}\")\n",
    "    print(f\"   â†’ Now it's standardized (meanâ‰ˆ0, stdâ‰ˆ1)!\")\n",
    "else:\n",
    "    print(f\"\\n   Features are now standardized (meanâ‰ˆ0, stdâ‰ˆ1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09415a6b-0b7f-4c87-8f0d-06177c3b08e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING LOGISTIC REGRESSION MODEL\n",
      "======================================================================\n",
      "\n",
      "ðŸŽ¯ Model: Logistic Regression\n",
      "   Why this model?\n",
      "   âœ“ Good for binary classification (high vs low severity)\n",
      "   âœ“ Fast to train\n",
      "   âœ“ Interpretable - I can see which features matter!\n",
      "   âœ“ Gives me coefficients to answer RQ2 and RQ3\n",
      "\n",
      "ðŸ”§ Setting up the model...\n",
      "âœ… Model created!\n",
      "   Parameters: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': 0.0, 'max_iter': 1000, 'n_jobs': None, 'penalty': 'deprecated', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "ðŸ‹ï¸ Training the model on {len(X_train_scaled)} accidents...\n",
      "   (This might take a few seconds...)\n",
      "\n",
      "âœ… Training complete!\n",
      "   The model has learned from the training data!\n",
      "   Number of iterations: 20\n",
      "\n",
      "ðŸ’¡ Now let's see how well it performs!\n"
     ]
    }
   ],
   "source": [
    "# TRAINING LOGISTIC REGRESSION MODEL\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING LOGISTIC REGRESSION MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Model: Logistic Regression\")\n",
    "print(\"   Why this model?\")\n",
    "print(\"   âœ“ Good for binary classification (high vs low severity)\")\n",
    "print(\"   âœ“ Fast to train\")\n",
    "print(\"   âœ“ Interpretable - I can see which features matter!\")\n",
    "print(\"   âœ“ Gives me coefficients to answer RQ2 and RQ3\")\n",
    "\n",
    "print(\"\\nðŸ”§ Setting up the model...\")\n",
    "\n",
    "# Create the logistic regression model\n",
    "# max_iter=1000 to make sure it converges\n",
    "# random_state=42 for reproducibility\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    solver='lbfgs'  # Good general-purpose solver\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model created!\")\n",
    "print(f\"   Parameters: {model.get_params()}\")\n",
    "\n",
    "print(\"\\nðŸ‹ï¸ Training the model on {len(X_train_scaled)} accidents...\")\n",
    "print(\"   (This might take a few seconds...)\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nâœ… Training complete!\")\n",
    "print(f\"   The model has learned from the training data!\")\n",
    "print(f\"   Number of iterations: {model.n_iter_[0]}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Now let's see how well it performs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042de138-90fd-430c-b3c5-88c812a81f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MAKING PREDICTIONS ON TEST SET\n",
      "======================================================================\n",
      "\n",
      "ðŸ”® Time to test the model!\n",
      "   The model has NEVER seen these 64 accidents before\n",
      "   Let's see if it can predict their severity correctly!\n",
      "\n",
      "âœ… Predictions made!\n",
      "\n",
      "ðŸ“Š Prediction summary:\n",
      "   Predicted HIGH severity: 61 accidents\n",
      "   Predicted LOW severity: 3 accidents\n",
      "\n",
      "ðŸ“Š Actual values in test set:\n",
      "   Actually HIGH severity: 51 accidents\n",
      "   Actually LOW severity: 13 accidents\n",
      "\n",
      "ðŸ’¡ Now let's calculate how accurate these predictions are!\n"
     ]
    }
   ],
   "source": [
    "# MAKING PREDICTIONS\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MAKING PREDICTIONS ON TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ”® Time to test the model!\")\n",
    "print(f\"   The model has NEVER seen these {len(X_test_scaled)} accidents before\")\n",
    "print(f\"   Let's see if it can predict their severity correctly!\")\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Also get prediction probabilities (useful for ROC curve later)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]  # Probability of class 1 (high severity)\n",
    "\n",
    "print(f\"\\nâœ… Predictions made!\")\n",
    "\n",
    "# Quick look at predictions\n",
    "print(f\"\\nðŸ“Š Prediction summary:\")\n",
    "print(f\"   Predicted HIGH severity: {(y_pred == 1).sum()} accidents\")\n",
    "print(f\"   Predicted LOW severity: {(y_pred == 0).sum()} accidents\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Actual values in test set:\")\n",
    "print(f\"   Actually HIGH severity: {y_test.sum()} accidents\")\n",
    "print(f\"   Actually LOW severity: {(y_test == 0).sum()} accidents\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Now let's calculate how accurate these predictions are!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a35334c-96b7-413b-a067-e6bbd7b90319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL PERFORMANCE EVALUATION\n",
      "======================================================================\n",
      "\n",
      "ðŸŽ¯ RQ1: How accurately can ML predict minor vs severe injuries?\n",
      "   Let's find out!\n",
      "\n",
      "ðŸ“Š PERFORMANCE METRICS:\n",
      "======================================================================\n",
      "\n",
      "âœ… ACCURACY: 0.781 (78.1%)\n",
      "   â†’ Out of 100 predictions, 78 are correct\n",
      "   â†’ This directly answers RQ1!\n",
      "\n",
      "âœ… PRECISION: 0.803 (80.3%)\n",
      "   â†’ When I predict 'high severity', I'm right 80% of the time\n",
      "   â†’ Important for resource allocation!\n",
      "\n",
      "âœ… RECALL: 0.961 (96.1%)\n",
      "   â†’ I correctly identify 96% of actual high severity accidents\n",
      "   â†’ Important for safety - don't want to miss severe accidents!\n",
      "\n",
      "âœ… F1-SCORE: 0.875\n",
      "   â†’ Balance between precision and recall\n",
      "   â†’ Good overall performance indicator\n",
      "\n",
      "âœ… ROC-AUC: 0.520\n",
      "   â†’ Measures model's ability to discriminate between classes\n",
      "   â†’ 0.5 = random, 1.0 = perfect\n",
      "   â†’ 0.520 is okay\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT:\n",
      "======================================================================\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Low Severity       0.33      0.08      0.12        13\n",
      "High Severity       0.80      0.96      0.88        51\n",
      "\n",
      "     accuracy                           0.78        64\n",
      "    macro avg       0.57      0.52      0.50        64\n",
      " weighted avg       0.71      0.78      0.72        64\n",
      "\n",
      "\n",
      "ðŸŽ¯ ANSWER TO RQ1:\n",
      "   Logistic Regression can predict accident severity with\n",
      "   78.1% accuracy!\n"
     ]
    }
   ],
   "source": [
    "# EVALUATING MODEL PERFORMANCE \n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL PERFORMANCE EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸŽ¯ RQ1: How accurately can ML predict minor vs severe injuries?\")\n",
    "print(\"   Let's find out!\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nðŸ“Š PERFORMANCE METRICS:\")\n",
    "print(f\"=\"*70)\n",
    "\n",
    "print(f\"\\nâœ… ACCURACY: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "print(f\"   â†’ Out of 100 predictions, {accuracy*100:.0f} are correct\")\n",
    "print(f\"   â†’ This directly answers RQ1!\")\n",
    "\n",
    "print(f\"\\nâœ… PRECISION: {precision:.3f} ({precision*100:.1f}%)\")\n",
    "print(f\"   â†’ When I predict 'high severity', I'm right {precision*100:.0f}% of the time\")\n",
    "print(f\"   â†’ Important for resource allocation!\")\n",
    "\n",
    "print(f\"\\nâœ… RECALL: {recall:.3f} ({recall*100:.1f}%)\")\n",
    "print(f\"   â†’ I correctly identify {recall*100:.0f}% of actual high severity accidents\")\n",
    "print(f\"   â†’ Important for safety - don't want to miss severe accidents!\")\n",
    "\n",
    "print(f\"\\nâœ… F1-SCORE: {f1:.3f}\")\n",
    "print(f\"   â†’ Balance between precision and recall\")\n",
    "print(f\"   â†’ Good overall performance indicator\")\n",
    "\n",
    "print(f\"\\nâœ… ROC-AUC: {roc_auc:.3f}\")\n",
    "print(f\"   â†’ Measures model's ability to discriminate between classes\")\n",
    "print(f\"   â†’ 0.5 = random, 1.0 = perfect\")\n",
    "print(f\"   â†’ {roc_auc:.3f} is {'excellent!' if roc_auc > 0.8 else 'good!' if roc_auc > 0.7 else 'okay'}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nðŸ“‹ DETAILED CLASSIFICATION REPORT:\")\n",
    "print(f\"=\"*70)\n",
    "print(classification_report(y_test, y_pred, target_names=['Low Severity', 'High Severity']))\n",
    "\n",
    "print(f\"\\nðŸŽ¯ ANSWER TO RQ1:\")\n",
    "print(f\"   Logistic Regression can predict accident severity with\")\n",
    "print(f\"   {accuracy*100:.1f}% accuracy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86206a57-6015-495f-9204-a7443564b853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
